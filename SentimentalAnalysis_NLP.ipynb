{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Majid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Majid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Majid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import re\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import multiprocessing as mp\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data. describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spltting the dataset\n",
    "train_reviews, test_reviews, train_sentiments, test_sentiments = train_test_split(data['review'], data['sentiment'], test_size=0.2, random_state=42 , stratify=data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((40000,), (40000,)), ((10000,), (10000,)))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_reviews.shape, train_sentiments.shape), (test_reviews.shape, test_sentiments.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In real-world applications, the model is trained on available data and then used to make predictions on new, unseen data. Setting aside a test set at the beginning helps replicate this scenario and gives a more accurate picture of how the model might perform post-deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Majid\\AppData\\Local\\Temp\\ipykernel_6936\\471995934.py:3: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    \n",
    "    # Remove non-letters\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    \n",
    "    # Convert to lowercase and tokenize\n",
    "    text = text.lower()\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    words = [w for w in words if w not in stopwords.words('english')]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(w) for w in words]\n",
    "    \n",
    "    # Join the words back into one string\n",
    "    text = ' '.join(words)\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the reviews in the training set\n",
    "train_reviews_clean = train_reviews.apply(clean_text)\n",
    "test_reviews_clean = test_reviews.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47808    caught little gem totally accident back reviva...\n",
       "20154    believe let movie accomplish favor friend ask ...\n",
       "43069    spoiler alert get nerve people remake use term...\n",
       "19413    one thing learnt watching george romero creeps...\n",
       "13673    remember theater review said horrible well thi...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reviews_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18870    yes mtv really way market daria started clever...\n",
       "39791    story bride fair amusing engaging one filmmake...\n",
       "30381    team varied scully mulder two scientist pilot ...\n",
       "42294    popular movie probably humor fast moving story...\n",
       "33480    movie made angry thinking new horror movie one...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_reviews_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW_cv_train: (40000, 6084975)\n",
      "BOW_cv_test: (10000, 6084975)\n"
     ]
    }
   ],
   "source": [
    "# Count vectorizer for bag of words\n",
    "cv = CountVectorizer(min_df=1, max_df=1, binary=False, ngram_range=(1,3))\n",
    "cv_train_reviews = cv.fit_transform(train_reviews_clean)\n",
    "cv_test_reviews = cv.transform(test_reviews_clean)\n",
    "\n",
    "print('BOW_cv_train:', cv_train_reviews.shape)\n",
    "print('BOW_cv_test:', cv_test_reviews.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf_train: (40000, 6084975)\n",
      "Tfidf_test: (10000, 6084975)\n"
     ]
    }
   ],
   "source": [
    "# Tfidf vectorizer\n",
    "tv = TfidfVectorizer(min_df=1, max_df=1, use_idf=True, ngram_range=(1,3))\n",
    "tv_train_reviews = tv.fit_transform(train_reviews_clean)\n",
    "tv_test_reviews = tv.transform(test_reviews_clean)\n",
    "\n",
    "print('Tfidf_train:', tv_train_reviews.shape)\n",
    "print('Tfidf_test:', tv_test_reviews.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "train_sentiments = lb.fit_transform(train_sentiments)\n",
    "test_sentiments = lb.transform(test_sentiments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " ...\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "train_sentiments = np.array(train_sentiments).astype('float32')\n",
    "test_sentiments = np.array(test_sentiments).astype('float32')\n",
    "print(train_sentiments)\n",
    "print(test_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, max_iter=500, random_state=42)\n",
      "LogisticRegression(C=1, max_iter=500, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2', max_iter=500, C=1, random_state=42)\n",
    "\n",
    "# Fitting the model for Bag of words\n",
    "lr_bow = lr.fit(cv_train_reviews, train_sentiments.ravel())\n",
    "print(lr_bow)\n",
    "\n",
    "# Fitting the model for TF-IDF features\n",
    "lr_tfidf = lr.fit(tv_train_reviews, train_sentiments.ravel())\n",
    "print(lr_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_bow_predictions = lr_bow.predict(cv_test_reviews)\n",
    "lr_bow_score = accuracy_score(test_sentiments, lr_bow_predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR with BOW Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.74      0.74      0.74      5000\n",
      "    Positive       0.74      0.74      0.74      5000\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.74      0.74      0.74     10000\n",
      "weighted avg       0.74      0.74      0.74     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for Logistic Regression with BOW\n",
    "lr_bow_report = classification_report(test_sentiments, lr_bow_predictions, target_names=['Negative', 'Positive'])\n",
    "print(\"LR with BOW Classification Report:\\n\", lr_bow_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR with TF-IDF Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.73      0.76      0.74      5000\n",
      "    Positive       0.75      0.72      0.73      5000\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.74      0.74      0.74     10000\n",
      "weighted avg       0.74      0.74      0.74     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Logistic Regression with TF-IDF\n",
    "lr_tfidf_predictions = lr_tfidf.predict(tv_test_reviews)\n",
    "lr_tfidf_score = accuracy_score(test_sentiments, lr_tfidf_predictions)\n",
    "\n",
    "# Classification report for Logistic Regression with TF-IDF\n",
    "lr_tfidf_report = classification_report(test_sentiments, lr_tfidf_predictions, target_names=['Negative', 'Positive'])\n",
    "print(\"LR with TF-IDF Classification Report:\\n\", lr_tfidf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "500/500 [==============================] - 132s 258ms/step - loss: 0.3666 - accuracy: 0.8400 - val_loss: 0.2960 - val_accuracy: 0.8810\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 124s 248ms/step - loss: 0.2523 - accuracy: 0.9010 - val_loss: 0.2910 - val_accuracy: 0.8789\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 104s 208ms/step - loss: 0.2115 - accuracy: 0.9199 - val_loss: 0.3105 - val_accuracy: 0.8745\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 103s 207ms/step - loss: 0.1785 - accuracy: 0.9317 - val_loss: 0.3334 - val_accuracy: 0.8702\n"
     ]
    }
   ],
   "source": [
    "max_words = 5000\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(train_reviews_clean)\n",
    "X_train = tokenizer.texts_to_sequences(train_reviews_clean)\n",
    "X_test = tokenizer.texts_to_sequences(test_reviews_clean)\n",
    "\n",
    "# Pad the sequences to have the same length\n",
    "max_sequence_length = 200\n",
    "X_train = pad_sequences(X_train, maxlen=max_sequence_length)\n",
    "X_test = pad_sequences(X_test, maxlen=max_sequence_length)\n",
    "\n",
    "# Define LSTM model structure\n",
    "model = Sequential()\n",
    "embedding_dim = 128\n",
    "model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_sequence_length))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the LSTM model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the LSTM model\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=2)\n",
    "history = model.fit(X_train, train_sentiments, batch_size=batch_size, epochs=epochs, validation_split=0.2, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing Model Performance:\n",
      "Logistic Regression BOW Accuracy: 0.7388\n",
      "Logistic Regression TF-IDF Accuracy: 0.7384\n",
      "LSTM Model Accuracy: 0.8705\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nComparing Model Performance:\")\n",
    "print(f\"Logistic Regression BOW Accuracy: {lr_bow_score:.4f}\")\n",
    "print(f\"Logistic Regression TF-IDF Accuracy: {lr_tfidf_score:.4f}\")\n",
    "print(f\"LSTM Model Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 19s 58ms/step - loss: 0.3373 - accuracy: 0.8705\n",
      "\n",
      "Comparing Model Performance:\n",
      "Logistic Regression BOW Accuracy: 0.7388\n",
      "Logistic Regression TF-IDF Accuracy: 0.7384\n",
      "LSTM Model Accuracy: 0.8705\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Logistic Regression with BOW\n",
    "lr_bow_score = lr_bow.score(cv_test_reviews, test_sentiments.ravel())\n",
    "\n",
    "# Evaluate Logistic Regression with TF-IDF\n",
    "lr_tfidf_score = lr_tfidf.score(tv_test_reviews, test_sentiments.ravel())\n",
    "\n",
    "# Evaluate LSTM model\n",
    "loss, accuracy = model.evaluate(X_test, test_sentiments)\n",
    "\n",
    "print(\"\\nComparing Model Performance:\")\n",
    "print(f\"Logistic Regression BOW Accuracy: {lr_bow_score:.4f}\")\n",
    "print(f\"Logistic Regression TF-IDF Accuracy: {lr_tfidf_score:.4f}\")\n",
    "print(f\"LSTM Model Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie fantastic', 'like film']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on new data using LSTM\n",
    "new_reviews = [\"This movie is fantastic!\", \"I didn't like this film at all.\"]\n",
    "new_reviews_clean = [clean_text(review) for review in new_reviews]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
